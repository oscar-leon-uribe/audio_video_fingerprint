{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram, resample\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import librosa.core as lr\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video fingerprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model and cut the last layer\n",
    "- For this case, i choose to use the values of the second fully connected layer as encoding for each frame, generating a vector of 4096 values and for the three frames a matrix of dimensions 3x4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save image from video\n",
    "- Load a video localy stored and save three images in different times\n",
    "- Reshape the images in the input format for the model (224x224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_frames(path_video, number_frames, space_frames, name, folder, size):\n",
    "    num_images = 0\n",
    "    label = 0\n",
    "    count = 0\n",
    "    success = True\n",
    "    vidcap = cv2.VideoCapture(path_video)\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    success, image = vidcap.read()\n",
    "    image = cv2.resize(image, size)\n",
    "    tensor_images = np.zeros([number_frames, image.shape[0],image.shape[1],image.shape[2]])\n",
    "\n",
    "    while success and num_images < number_frames:\n",
    "        success, image = vidcap.read()\n",
    "        image = cv2.resize(image, size)\n",
    "        tensor_images[num_images, :, :, :] = image\n",
    "        label += 1\n",
    "        num_images += 1\n",
    "        file_name = name + \"_\" + str(label) + \".jpg\"\n",
    "        path = os.path.join(folder, file_name)\n",
    "        cv2.imwrite(path, image)\n",
    "        count += fps*10\n",
    "        vidcap.set(1, count)\n",
    "    return tensor_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_video = 'videos/l4dSZD3YQ_M.mp4'\n",
    "size = (224, 224)\n",
    "folder = 'videos'\n",
    "name = 'vid_pics'\n",
    "number_frames = 4\n",
    "success = True\n",
    "space_frames = 10\n",
    "tensor_images = video_frames(path_video, number_frames, space_frames, name, folder, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case, I selected four images of a video and created an encoding for this images, for real video fingerprinting, I propose the following approach, create an encoding for each frame and compare against other videos using distance metrics (cosine distance) and after certain threshold that image is considered equal enough.\n",
    "- Is also possible to use another fully connected layer and check perfomance, also use techniques of dimensionality reduction in order to make more light the storage and processing of the fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fpprint = model.predict(tensor_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4096)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_fpprint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.3146102 , 0.        , ..., 3.040018  , 0.95649546,\n",
       "        0.        ],\n",
       "       [0.        , 0.93853045, 0.        , ..., 3.1489646 , 0.65248597,\n",
       "        0.        ],\n",
       "       [0.        , 1.0234423 , 0.        , ..., 3.0373263 , 0.5282865 ,\n",
       "        0.        ],\n",
       "       [0.        , 1.554539  , 0.        , ..., 3.3475573 , 0.5757041 ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_fpprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of the functions use are taking from the following repo : https://github.com/notexactlyawe/abracadabra\n",
    "- And as reference the following paper: Avery Li-Chun Wang, An Industrial-Strength Audio Search Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the spectogram from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_spectrogram(audio, sample_rate):\n",
    "    nperseg = int(sample_rate / 10)\n",
    "    return spectrogram(audio, sample_rate, nperseg=nperseg)\n",
    "\n",
    "def lr_file_to_spectrogram(filename):\n",
    "    audio, rate = lr.load(filename, sr=11025, mono=True)\n",
    "    return my_spectrogram(audio, 11025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find peaks in the spectogram and hash values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_within(center, distance, shape):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x in range(-distance, distance+1):\n",
    "        y_min = -(distance - abs(x))\n",
    "        y_max = distance - abs(x)\n",
    "        for y in range(y_min, y_max+1):\n",
    "            if x == 0 and y == 0:\n",
    "                continue\n",
    "            new_x = center[1] + x\n",
    "            new_y = center[0] + y\n",
    "            if new_x < 0 or new_x >= shape[1]:\n",
    "                continue\n",
    "            if new_y < 0 or new_y >= shape[0]:\n",
    "                continue\n",
    "            ys.append(center[0] + y)\n",
    "            xs.append(center[1] + x)\n",
    "    return ys, xs\n",
    "\n",
    "def find_peaks_fast(arr, distance, point_efficiency=0.4):\n",
    "    i = arr.argsort(axis=None)[::-1]\n",
    "    j = np.vstack(np.unravel_index(i, arr.shape)).T\n",
    "    peaks = []\n",
    "    total = j.size\n",
    "    e_peaks = (total / (distance**2)) * point_efficiency\n",
    "    for point in j:\n",
    "        if len(peaks) > e_peaks:\n",
    "            break\n",
    "        for peak in peaks:\n",
    "            if abs(point[0] - peak[0]) + abs(point[1] - peak[1]) < distance:\n",
    "                break\n",
    "        else:\n",
    "            peaks.append(point)\n",
    "    print()\n",
    "    return peaks\n",
    "\n",
    "def target_zone(anchor, points, width, height, t):\n",
    "    x_min = anchor[1] + t\n",
    "    x_max = x_min + width\n",
    "    y_min = anchor[0] - (height*0.5)\n",
    "    y_max = y_min + height\n",
    "    for point in points:\n",
    "        if point[0] < y_min or point[0] > y_max:\n",
    "            continue\n",
    "        if point[1] < x_min or point[1] > x_max:\n",
    "            continue\n",
    "        yield point\n",
    "        \n",
    "def hash_point_pair(p1, p2):\n",
    "    return hash((p1[0], p2[0], p2[1]-p2[1]))\n",
    "\n",
    "def hash_points(points, filename):\n",
    "    hashes = []\n",
    "    for anchor in points:\n",
    "        for target in target_zone(anchor, points, 1, 2000, 0.1):\n",
    "            hashes.append((hash_point_pair(anchor, target), anchor[1], filename))\n",
    "    return hashes\n",
    "\n",
    "def indices_to_tf_pairs(idxs, t, f):\n",
    "    return np.array([(f[i[0]], t[i[1]]) for i in idxs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calulate the hash for a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_song(filename, distance=20):\n",
    "    f, t, Sxx = lr_file_to_spectrogram(filename)\n",
    "    peaks = find_peaks_fast(Sxx, distance)\n",
    "    peaks = indices_to_tf_pairs(peaks, t, f)\n",
    "    h = hash_points(peaks, filename)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(test_hashes, hash_db):\n",
    "    results = defaultdict(list)\n",
    "    for h in test_hashes:\n",
    "        if str(h[0]) in hash_db.columns:\n",
    "            filename = hash_db[str(h[0])][0]\n",
    "            offset   = float(hash_db[str(h[0])][1])\n",
    "            results[filename].append(offset)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(test_hashes, hash_db):\n",
    "    results = defaultdict(list)\n",
    "    for h in test_hashes.iterrows():\n",
    "        h = h[1]\n",
    "        if str(h[0]) in hash_db.columns:\n",
    "            filename = hash_db[str(h[0])][0]\n",
    "            offset   = float(hash_db[str(h[0])][1])\n",
    "            results[filename].append(offset)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_song(matches):\n",
    "    f_len = []\n",
    "    for f, m in matches.items():\n",
    "        if len(m) < 10:\n",
    "            continue\n",
    "\n",
    "        f_len.append((f, len(m)/(np.std(m) + np.max(m)), len(m)))\n",
    "    f_len = sorted(f_len, key=itemgetter(1), reverse=True)\n",
    "    if (f_len[0][1]>10) and (len(f_len))>0:\n",
    "        return f_len[0][0]\n",
    "    else:\n",
    "        return 'No match'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create database of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hash_db = {}\n",
    "data = [\"songs/metallica_the_unforgiven.wav\"\n",
    "     , \"songs/bruno_mars.wav\"\n",
    "     , \"songs/one_republic_counting_stars.wav\"\n",
    "    , \"songs/michael_beat_it.wav\"]\n",
    "for file in data:\n",
    "    hashes = register_song(file)\n",
    "    filename = file.split('/')[-1]\n",
    "    for h, offset, _ in hashes:\n",
    "        hash_db[h] = filename, offset\n",
    "\n",
    "files = defaultdict(int)\n",
    "for h, f in hash_db.items():\n",
    "    files[f[0]] += 1\n",
    "pd.DataFrame(hash_db).to_csv('music_database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hash of test songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## don't run on git because the songs are to heavy for upload\n",
    "test_song_no_match = register_song(\"songs/coldplay_the_scientist.wav\")\n",
    "test_song_match = register_song(\"songs/one_republic_counting_stars.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_song_no_match).to_csv('coldplay_the_scientist.csv')\n",
    "pd.DataFrame(test_song_match).to_csv('one_republic_counting_stars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldplay = pd.read_csv('coldplay_the_scientist.csv').drop(columns='Unnamed: 0')\n",
    "one_republic = pd.read_csv('one_republic_counting_stars.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_db = pd.read_csv('music_database.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the porpuse of testing i loaded two songs, one that is in the database and another that is not.\n",
    "- The scientist by coldplay is not in the database and counting stars by one republic is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldplay_matches = find_matches(coldplay, music_db)\n",
    "one_republic_matches = find_matches(one_republic, music_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No match'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_song(coldplay_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one_republic_counting_stars.wav'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_song(one_republic_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
